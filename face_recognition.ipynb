{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d296507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU instead\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from utils.system import get_available_device\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "\n",
    "device = get_available_device()\n",
    "\n",
    "KNOWN_FACES_PATH='./known_faces'\n",
    "\n",
    "# Model\n",
    "detector_model = YOLO(\"./best_models/yolo_decoder_best.pt\").to(device)\n",
    "classifier_model = InceptionResnetV1(pretrained='vggface2', num_classes=2, device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37abeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_embeddings = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb88a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.uint8, scale=True),\n",
    "    v2.Resize((160, 160)),  # Измените размер под вашу модель\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "def compare_embeddings(embedding, threshold=0.7):\n",
    "    best_match = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for name, known_person_embeddings in known_embeddings.items():\n",
    "        for embeddings in known_person_embeddings:\n",
    "            distance = F.pairwise_distance(embedding, embeddings)\n",
    "\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                best_match = name\n",
    "\n",
    "    if min_distance <= threshold:\n",
    "        return best_match\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def detect_faces(image):\n",
    "    with torch.no_grad():  # Отключите вычисление градиентов во время инференса\n",
    "        result = detector_model([image])[0]\n",
    "    \n",
    "    return result.boxes.xyxy\n",
    "    \n",
    "        \n",
    "def recognize_faces(image, boxes):\n",
    "    cropped_faces = [\n",
    "        transform(image.crop(list(map(float,bbox))))\n",
    "        for bbox in boxes\n",
    "    ]\n",
    "    if cropped_faces:  # Убедитесь, что список не пустой\n",
    "        face_tensors = torch.stack(cropped_faces)\n",
    "        embeddings = classifier_model(face_tensors)\n",
    "    else:\n",
    "        embeddings = torch.empty(0)\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2810e651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 face, 82.1ms\n",
      "Speed: 4.3ms preprocess, 82.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 57.9ms\n",
      "Speed: 3.8ms preprocess, 57.9ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 81.3ms\n",
      "Speed: 3.5ms preprocess, 81.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 105.9ms\n",
      "Speed: 5.1ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 70.8ms\n",
      "Speed: 4.0ms preprocess, 70.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 66.4ms\n",
      "Speed: 3.2ms preprocess, 66.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 69.8ms\n",
      "Speed: 2.8ms preprocess, 69.8ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 face, 61.3ms\n",
      "Speed: 3.2ms preprocess, 61.3ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "from utils.system import get_last_dirname\n",
    "\n",
    "\n",
    "for path_dir, dir_list, file_list in os.walk(KNOWN_FACES_PATH):\n",
    "    for file_path in file_list:\n",
    "        image_path = os.path.join(path_dir, file_path)\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        boxes = detect_faces(image)\n",
    "        embeddings = recognize_faces(image, boxes)\n",
    "        \n",
    "        name = get_last_dirname(path_dir)\n",
    "        known_embeddings[name].append(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9676f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 face, 58.0ms\n",
      "Speed: 3.6ms preprocess, 58.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 56.8ms\n",
      "Speed: 2.1ms preprocess, 56.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.5ms\n",
      "Speed: 2.5ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 63.7ms\n",
      "Speed: 2.2ms preprocess, 63.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 60.7ms\n",
      "Speed: 2.2ms preprocess, 60.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 52.6ms\n",
      "Speed: 2.1ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.5ms\n",
      "Speed: 1.9ms preprocess, 51.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 62.9ms\n",
      "Speed: 1.8ms preprocess, 62.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.8ms\n",
      "Speed: 1.8ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 1.8ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.4ms\n",
      "Speed: 1.8ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.4ms\n",
      "Speed: 1.8ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 1.7ms preprocess, 47.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.8ms\n",
      "Speed: 1.9ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.6ms\n",
      "Speed: 1.8ms preprocess, 48.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.7ms\n",
      "Speed: 1.7ms preprocess, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.4ms\n",
      "Speed: 1.7ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.0ms\n",
      "Speed: 1.7ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.5ms\n",
      "Speed: 1.7ms preprocess, 47.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.3ms\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 49.2ms\n",
      "Speed: 1.7ms preprocess, 49.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.7ms\n",
      "Speed: 1.8ms preprocess, 47.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.7ms\n",
      "Speed: 1.7ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.8ms\n",
      "Speed: 1.7ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.2ms\n",
      "Speed: 1.7ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 49.5ms\n",
      "Speed: 1.8ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.8ms\n",
      "Speed: 1.8ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.1ms\n",
      "Speed: 1.8ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.4ms\n",
      "Speed: 1.9ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 49.9ms\n",
      "Speed: 1.8ms preprocess, 49.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 52.8ms\n",
      "Speed: 1.8ms preprocess, 52.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.1ms\n",
      "Speed: 1.8ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.6ms\n",
      "Speed: 1.8ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.0ms\n",
      "Speed: 1.8ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.6ms\n",
      "Speed: 1.9ms preprocess, 48.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 49.0ms\n",
      "Speed: 1.7ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.8ms\n",
      "Speed: 1.7ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.1ms\n",
      "Speed: 1.7ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 52.0ms\n",
      "Speed: 1.7ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.1ms\n",
      "Speed: 1.7ms preprocess, 47.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 1.7ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.5ms\n",
      "Speed: 1.7ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 1.9ms preprocess, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.8ms\n",
      "Speed: 1.8ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.9ms\n",
      "Speed: 1.8ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.7ms\n",
      "Speed: 1.7ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.1ms\n",
      "Speed: 1.8ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.9ms\n",
      "Speed: 1.8ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.0ms\n",
      "Speed: 1.7ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.9ms\n",
      "Speed: 1.8ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.6ms\n",
      "Speed: 1.7ms preprocess, 48.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.4ms\n",
      "Speed: 1.8ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.0ms\n",
      "Speed: 1.7ms preprocess, 48.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.6ms\n",
      "Speed: 1.8ms preprocess, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.0ms\n",
      "Speed: 1.7ms preprocess, 48.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.1ms\n",
      "Speed: 1.7ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.2ms\n",
      "Speed: 1.7ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 47.8ms\n",
      "Speed: 1.8ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 1.7ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 2.1ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.2ms\n",
      "Speed: 1.8ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.5ms\n",
      "Speed: 1.8ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.9ms\n",
      "Speed: 1.8ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 52.6ms\n",
      "Speed: 2.0ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 62.1ms\n",
      "Speed: 2.0ms preprocess, 62.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.1ms\n",
      "Speed: 1.8ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 1.9ms preprocess, 45.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.8ms\n",
      "Speed: 1.8ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 1.9ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 1.8ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 1.8ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 1.9ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 1.8ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 1.9ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 1.8ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.8ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 1.9ms preprocess, 46.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 1.8ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.7ms\n",
      "Speed: 1.9ms preprocess, 48.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 1.8ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 1.8ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 46.3ms\n",
      "Speed: 1.8ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 48.0ms\n",
      "Speed: 1.9ms preprocess, 48.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 45.7ms\n",
      "Speed: 1.9ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 44.9ms\n",
      "Speed: 1.9ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 44.1ms\n",
      "Speed: 1.7ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 51.7ms\n",
      "Speed: 1.9ms preprocess, 51.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 46.3ms\n",
      "Speed: 1.9ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 47.3ms\n",
      "Speed: 1.9ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 48.2ms\n",
      "Speed: 1.9ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 46.0ms\n",
      "Speed: 1.9ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 1.8ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 1.9ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 1.9ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 1.9ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 1.9ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 1.8ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 1.8ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 1.8ms preprocess, 46.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.4ms\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.4ms\n",
      "Speed: 1.9ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 1.9ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 1.9ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 1.8ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 1.9ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.1ms\n",
      "Speed: 2.1ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 1.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 1.9ms preprocess, 46.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 1.9ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 1.9ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 42.8ms\n",
      "Speed: 2.0ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 42.8ms\n",
      "Speed: 2.0ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 1.9ms preprocess, 49.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 2.3ms preprocess, 45.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 2.1ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.5ms\n",
      "Speed: 1.9ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.3ms\n",
      "Speed: 2.0ms preprocess, 49.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.0ms\n",
      "Speed: 2.1ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.7ms\n",
      "Speed: 1.9ms preprocess, 50.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.8ms\n",
      "Speed: 1.9ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.9ms\n",
      "Speed: 2.2ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 1.9ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.7ms\n",
      "Speed: 2.1ms preprocess, 44.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.2ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.8ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.0ms\n",
      "Speed: 1.9ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 2.1ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.6ms\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.2ms\n",
      "Speed: 2.1ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.8ms\n",
      "Speed: 1.9ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 42.7ms\n",
      "Speed: 1.9ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.1ms\n",
      "Speed: 2.3ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.5ms\n",
      "Speed: 2.1ms preprocess, 49.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 1.9ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.2ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 2.1ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 1.9ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.1ms\n",
      "Speed: 2.1ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.6ms\n",
      "Speed: 2.0ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 52.0ms\n",
      "Speed: 2.1ms preprocess, 52.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.3ms\n",
      "Speed: 2.1ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.9ms\n",
      "Speed: 2.1ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.4ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.3ms\n",
      "Speed: 2.1ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.9ms\n",
      "Speed: 2.1ms preprocess, 43.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.9ms\n",
      "Speed: 2.1ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.8ms\n",
      "Speed: 2.1ms preprocess, 48.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.2ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 1.9ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.4ms\n",
      "Speed: 2.0ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.8ms\n",
      "Speed: 1.9ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 43.6ms\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.1ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.2ms\n",
      "Speed: 1.9ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.2ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.2ms\n",
      "Speed: 1.9ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 1.9ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 2.1ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.1ms\n",
      "Speed: 2.1ms preprocess, 47.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 2.1ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 2.1ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.7ms\n",
      "Speed: 2.0ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.1ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.7ms\n",
      "Speed: 2.3ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 2.2ms preprocess, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.1ms\n",
      "Speed: 2.1ms preprocess, 48.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 2.1ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 2.0ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 2.1ms preprocess, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.2ms preprocess, 45.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 2.1ms preprocess, 48.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.5ms\n",
      "Speed: 2.1ms preprocess, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.1ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.1ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.0ms\n",
      "Speed: 2.2ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.0ms\n",
      "Speed: 2.1ms preprocess, 50.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 46.8ms\n",
      "Speed: 2.2ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.1ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.1ms\n",
      "Speed: 2.1ms preprocess, 47.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.4ms\n",
      "Speed: 2.2ms preprocess, 54.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.8ms\n",
      "Speed: 2.2ms preprocess, 53.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.9ms\n",
      "Speed: 2.1ms preprocess, 48.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.1ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.2ms\n",
      "Speed: 2.0ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.6ms\n",
      "Speed: 2.3ms preprocess, 50.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.6ms\n",
      "Speed: 2.1ms preprocess, 48.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.9ms\n",
      "Speed: 2.6ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 2.7ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.3ms\n",
      "Speed: 2.4ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.8ms\n",
      "Speed: 2.1ms preprocess, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.1ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.6ms\n",
      "Speed: 2.2ms preprocess, 54.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.8ms\n",
      "Speed: 2.1ms preprocess, 48.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.0ms\n",
      "Speed: 2.2ms preprocess, 50.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.1ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 2.3ms preprocess, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.1ms\n",
      "Speed: 2.1ms preprocess, 48.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.0ms\n",
      "Speed: 2.1ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.1ms\n",
      "Speed: 2.1ms preprocess, 47.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.5ms\n",
      "Speed: 2.1ms preprocess, 46.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.4ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.8ms\n",
      "Speed: 2.1ms preprocess, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.2ms\n",
      "Speed: 2.2ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.1ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 57.8ms\n",
      "Speed: 2.2ms preprocess, 57.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.1ms\n",
      "Speed: 2.1ms preprocess, 50.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.5ms\n",
      "Speed: 2.1ms preprocess, 50.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.8ms\n",
      "Speed: 2.3ms preprocess, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.5ms\n",
      "Speed: 2.1ms preprocess, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.5ms\n",
      "Speed: 2.1ms preprocess, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.0ms\n",
      "Speed: 2.1ms preprocess, 49.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.8ms\n",
      "Speed: 2.1ms preprocess, 48.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.7ms\n",
      "Speed: 2.1ms preprocess, 48.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.3ms\n",
      "Speed: 2.3ms preprocess, 47.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.3ms\n",
      "Speed: 2.0ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.1ms\n",
      "Speed: 2.2ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.8ms\n",
      "Speed: 2.2ms preprocess, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.4ms\n",
      "Speed: 2.2ms preprocess, 48.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.4ms\n",
      "Speed: 2.1ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.5ms\n",
      "Speed: 2.1ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.9ms\n",
      "Speed: 2.1ms preprocess, 48.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.9ms\n",
      "Speed: 2.1ms preprocess, 49.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.8ms\n",
      "Speed: 2.1ms preprocess, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 45.9ms\n",
      "Speed: 2.1ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.9ms\n",
      "Speed: 2.1ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.2ms\n",
      "Speed: 2.2ms preprocess, 49.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.7ms\n",
      "Speed: 2.2ms preprocess, 48.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.1ms\n",
      "Speed: 2.1ms preprocess, 49.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.8ms\n",
      "Speed: 2.2ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.0ms\n",
      "Speed: 2.4ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 2.4ms preprocess, 49.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.5ms\n",
      "Speed: 2.1ms preprocess, 49.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.2ms\n",
      "Speed: 2.4ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 56.6ms\n",
      "Speed: 2.1ms preprocess, 56.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 55.7ms\n",
      "Speed: 2.3ms preprocess, 55.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 56.2ms\n",
      "Speed: 2.3ms preprocess, 56.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 66.7ms\n",
      "Speed: 2.3ms preprocess, 66.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.4ms\n",
      "Speed: 2.2ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.2ms\n",
      "Speed: 2.2ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.1ms\n",
      "Speed: 2.2ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.0ms\n",
      "Speed: 2.2ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.0ms\n",
      "Speed: 2.2ms preprocess, 50.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 2.1ms preprocess, 49.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.4ms\n",
      "Speed: 2.3ms preprocess, 53.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 60.4ms\n",
      "Speed: 2.4ms preprocess, 60.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 59.1ms\n",
      "Speed: 2.5ms preprocess, 59.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 57.9ms\n",
      "Speed: 2.4ms preprocess, 57.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 59.5ms\n",
      "Speed: 2.4ms preprocess, 59.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 60.4ms\n",
      "Speed: 2.5ms preprocess, 60.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 60.1ms\n",
      "Speed: 3.0ms preprocess, 60.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 72.5ms\n",
      "Speed: 3.9ms preprocess, 72.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 67.5ms\n",
      "Speed: 3.1ms preprocess, 67.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 64.9ms\n",
      "Speed: 2.3ms preprocess, 64.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 59.1ms\n",
      "Speed: 2.8ms preprocess, 59.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.2ms\n",
      "Speed: 2.3ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.2ms\n",
      "Speed: 2.1ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 52.6ms\n",
      "Speed: 2.2ms preprocess, 52.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.6ms\n",
      "Speed: 2.1ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 53.0ms\n",
      "Speed: 2.2ms preprocess, 53.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.2ms\n",
      "Speed: 2.1ms preprocess, 51.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.1ms\n",
      "Speed: 2.1ms preprocess, 50.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 59.5ms\n",
      "Speed: 2.1ms preprocess, 59.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 56.8ms\n",
      "Speed: 2.0ms preprocess, 56.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.6ms\n",
      "Speed: 2.2ms preprocess, 54.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.7ms\n",
      "Speed: 2.0ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.5ms\n",
      "Speed: 2.1ms preprocess, 50.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.0ms\n",
      "Speed: 2.1ms preprocess, 50.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.9ms\n",
      "Speed: 2.0ms preprocess, 50.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 54.5ms\n",
      "Speed: 2.2ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 50.1ms\n",
      "Speed: 2.2ms preprocess, 50.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.5ms\n",
      "Speed: 2.2ms preprocess, 48.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 57.1ms\n",
      "Speed: 2.1ms preprocess, 57.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.2ms\n",
      "Speed: 3.1ms preprocess, 80.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 62.8ms\n",
      "Speed: 2.3ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 88.4ms\n",
      "Speed: 6.0ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 73.6ms\n",
      "Speed: 2.8ms preprocess, 73.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 57.9ms\n",
      "Speed: 2.2ms preprocess, 57.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 63.7ms\n",
      "Speed: 2.5ms preprocess, 63.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 58.0ms\n",
      "Speed: 2.4ms preprocess, 58.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 59.0ms\n",
      "Speed: 2.4ms preprocess, 59.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\u001b[32m     33\u001b[39m pil_image = Image.fromarray(frame_rgb)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m boxes = \u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m embeddings = recognize_faces(pil_image, boxes)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bbox, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(boxes, embeddings):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mdetect_faces\u001b[39m\u001b[34m(image)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_faces\u001b[39m(image):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():  \u001b[38;5;66;03m# Отключите вычисление градиентов во время инференса\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         result = \u001b[43mdetector_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.boxes.xyxy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/engine/model.py:181\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, source, stream, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    154\u001b[39m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image.Image, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np.ndarray, torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    155\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    156\u001b[39m     **kwargs: Any,\n\u001b[32m    157\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m    158\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[32m    160\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m \u001b[33;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/engine/model.py:549\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/engine/predictor.py:218\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/utils/_contextlib.py:35\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     39\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/engine/predictor.py:329\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.embed:\n\u001b[32m    331\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/engine/predictor.py:173\u001b[39m, in \u001b[36mBasePredictor.inference\u001b[39m\u001b[34m(self, im, *args, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[32m    168\u001b[39m visualize = (\n\u001b[32m    169\u001b[39m     increment_path(\u001b[38;5;28mself\u001b[39m.save_dir / Path(\u001b[38;5;28mself\u001b[39m.batch[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).stem, mkdir=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.visualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.tensor)\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    172\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/autobackend.py:592\u001b[39m, in \u001b[36mAutoBackend.forward\u001b[39m\u001b[34m(self, im, augment, visualize, embed, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nn_module:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/tasks.py:120\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/tasks.py:138\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/tasks.py:159\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    160\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:336\u001b[39m, in \u001b[36mC3.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    335\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Forward pass through the CSP bottleneck with 3 convolutions.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv3(torch.cat((\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.cv2(x)), \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:476\u001b[39m, in \u001b[36mBottleneck.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    475\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv2(\u001b[38;5;28mself\u001b[39m.cv1(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/ultralytics/nn/modules/conv.py:91\u001b[39m, in \u001b[36mConv.forward_fuse\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/university/Дипломы/Никита/project/venv_yolo/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    454\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    455\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "# 2.  Захват видео с веб-камеры\n",
    "cap = cv2.VideoCapture(0)  # 0 - индекс веб-камеры по умолчанию. Измените, если у вас несколько камер.\n",
    "\n",
    "\n",
    "# Проверка, успешно ли открыта веб-камера\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Не удается открыть веб-камеру\")\n",
    "\n",
    "\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "fps = 0\n",
    "\n",
    "# 3. Основной цикл обработки кадров\n",
    "while(True):\n",
    "    # Считываем кадр с веб-камеры\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Если кадр не был успешно считан, выходим из цикла\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(frame_rgb)\n",
    "    \n",
    "    boxes = detect_faces(pil_image)\n",
    "    embeddings = recognize_faces(pil_image, boxes)\n",
    "    \n",
    "    for bbox, embedding in zip(boxes, embeddings):\n",
    "        x1 = int(bbox[0])\n",
    "        y1 = int(bbox[1])\n",
    "        x2 = int(bbox[2])\n",
    "        y2 = int(bbox[3])\n",
    "        \n",
    "        name = compare_embeddings(embedding) or 'Unknown'\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{name}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "    if elapsed_time > 1:  # Обновляем FPS каждую секунду\n",
    "        fps = frame_count / elapsed_time\n",
    "        start_time = time.time()\n",
    "        frame_count = 0\n",
    "\n",
    "    # Добавим FPS на кадр для отображения на экране\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # 7. Отображение результата\n",
    "    cv2.imshow('Обнаружение лиц', frame)\n",
    "\n",
    "    # 8. Выход из цикла при нажатии клавиши 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "# 9. Освобождение ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
